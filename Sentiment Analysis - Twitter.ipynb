{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the required libraries to extract data from twitter and for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from tweepy import OAuthHandler\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting Twitter API keys\n",
    "In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: API key, API secret, Access token and Access token secret. Follow the steps below to get all 4 elements:\n",
    "\n",
    "1) Create a twitter account if you do not already have one.\n",
    "2) Go to https://apps.twitter.com/ and log in with your twitter credentials.\n",
    "3) Click \"Create New App\"\n",
    "4) Fill out the form, agree to the terms, and click \"Create your Twitter application\"\n",
    "5) In the next page, click on \"API keys\" tab, and copy your \"API key\" and \"API secret\".\n",
    "6) Scroll down and click \"Create my access token\", and copy your \"Access token\" and \"Access token secret\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Connecting to Twitter Streaming API and downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'L5a3avLNGPXmKw3PD313KKN7t'\n",
    "consumer_secret = 'oPP1FKnYU2wVVluyNBH0EOLqw0TNgVxS82wubNU7gNDtRCMjT4'\n",
    "access_token = '968883773495443458-FcbinMeZCT9D4x3LjmumuvzkfXiNJLP'\n",
    "access_secret = 'UfSHf6c88NPBpOaXpVqL8X6TJSQoRpNibTXKXJahD2LDd'\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Extact the data and write it to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open/create a file to append data to\n",
    "csvFile = open('13ReasonsWhy_1.csv', 'a')\n",
    "\n",
    "#Use csv writer\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "for tweet in tweepy.Cursor(api.search,\n",
    "                           q = \"13ReasonsWhy\",\n",
    "                           since = \"2018-04-23\",\n",
    "                           until = \"2018-04-24\",\n",
    "                           lang = \"en\").items():\n",
    "\n",
    "    # Write a row to the CSV file. I use encode UTF-8\n",
    "    #csvWriter.writerow([tweet.text.encode('utf-8')])\n",
    "    #csvWriter.writerow([tweet.text.encode('utf-8')])\n",
    "    print (tweet.text)\n",
    "    print(tweet.get)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_csv(\"C://Users//Aswathi//13ReasonsWhy.csv\",names = {\"Tweet\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Data Cleaning by removing symbols, @ and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'@johnkrasinski I saw @quietplacemovie on mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'RT @quietplacemovie: Silence is golden. Expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'If you wanna know how they felt in @quietpla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'RT @quietplacemovie: \\xe2\\x80\\x9cMy job is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'@capegirl8 @quietplacemovie Always down for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  b'@johnkrasinski I saw @quietplacemovie on mon...\n",
       "1  b'RT @quietplacemovie: Silence is golden. Expe...\n",
       "2  b'If you wanna know how they felt in @quietpla...\n",
       "3  b'RT @quietplacemovie: \\xe2\\x80\\x9cMy job is t...\n",
       "4  b'@capegirl8 @quietplacemovie Always down for ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aswathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(0,len(twitter)):\n",
    "    data = re.sub('[^a-zA-Z]',' ',twitter.loc[i,\"Tweet\"])\n",
    "    data = data[2:]\n",
    "    data = data.lower()\n",
    "    data = word_tokenize(data)\n",
    "    lem = WordNetLemmatizer()\n",
    "    data = [lem.lemmatize(word) for word in data if not word in set(stopwords.words('english'))]\n",
    "    data = ' '.join(data)\n",
    "    l.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter['clean_Tweet'] = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>clean_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'@johnkrasinski I saw @quietplacemovie on mon...</td>\n",
       "      <td>johnkrasinski saw quietplacemovie monday tryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'RT @quietplacemovie: Silence is golden. Expe...</td>\n",
       "      <td>rt quietplacemovie silence golden experience a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'If you wanna know how they felt in @quietpla...</td>\n",
       "      <td>wan na know felt quietplacemovie order l popco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'RT @quietplacemovie: \\xe2\\x80\\x9cMy job is t...</td>\n",
       "      <td>rt quietplacemovie xe x x cmy job tell story f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'@capegirl8 @quietplacemovie Always down for ...</td>\n",
       "      <td>capegirl quietplacemovie always movie date xf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  b'@johnkrasinski I saw @quietplacemovie on mon...   \n",
       "1  b'RT @quietplacemovie: Silence is golden. Expe...   \n",
       "2  b'If you wanna know how they felt in @quietpla...   \n",
       "3  b'RT @quietplacemovie: \\xe2\\x80\\x9cMy job is t...   \n",
       "4  b'@capegirl8 @quietplacemovie Always down for ...   \n",
       "\n",
       "                                         clean_Tweet  \n",
       "0  johnkrasinski saw quietplacemovie monday tryin...  \n",
       "1  rt quietplacemovie silence golden experience a...  \n",
       "2  wan na know felt quietplacemovie order l popco...  \n",
       "3  rt quietplacemovie xe x x cmy job tell story f...  \n",
       "4  capegirl quietplacemovie always movie date xf ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.DataFrame(twitter['clean_Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = df_twitter.drop_duplicates().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.DataFrame(twitter['clean_Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnkrasinski saw quietplacemovie monday tryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt quietplacemovie silence golden experience a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wan na know felt quietplacemovie order l popco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt quietplacemovie xe x x cmy job tell story f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capegirl quietplacemovie always movie date xf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_Tweet\n",
       "0  johnkrasinski saw quietplacemovie monday tryin...\n",
       "1  rt quietplacemovie silence golden experience a...\n",
       "2  wan na know felt quietplacemovie order l popco...\n",
       "3  rt quietplacemovie xe x x cmy job tell story f...\n",
       "4  capegirl quietplacemovie always movie date xf ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 : Calculate the polarity of the tweets using TextBlob package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df_twitter)):\n",
    "    blob = TextBlob(df_twitter.loc[i,\"clean_Tweet\"])\n",
    "    df_twitter.loc[i,'polarity'] = blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Tweet</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnkrasinski saw quietplacemovie monday tryin...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt quietplacemovie silence golden experience a...</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wan na know felt quietplacemovie order l popco...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt quietplacemovie xe x x cmy job tell story f...</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capegirl quietplacemovie always movie date xf ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_Tweet  polarity\n",
       "0  johnkrasinski saw quietplacemovie monday tryin...  0.000000\n",
       "1  rt quietplacemovie silence golden experience a...  0.300000\n",
       "2  wan na know felt quietplacemovie order l popco...  0.066667\n",
       "3  rt quietplacemovie xe x x cmy job tell story f...  0.285714\n",
       "4  capegirl quietplacemovie always movie date xf ...  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 : Convert the polarity into sentiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df_twitter)):\n",
    "    if(df_twitter.loc[i,\"polarity\"] > 0) :\n",
    "        df_twitter.loc[i,'sentiment'] = 1\n",
    "    else:\n",
    "        if(df_twitter.loc[i,\"polarity\"] < 0):\n",
    "            df_twitter.loc[i,'sentiment'] = -1\n",
    "        else:\n",
    "            df_twitter.loc[i,'sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_Tweet</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnkrasinski saw quietplacemovie monday tryin...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt quietplacemovie silence golden experience a...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wan na know felt quietplacemovie order l popco...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rt quietplacemovie xe x x cmy job tell story f...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capegirl quietplacemovie always movie date xf ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_Tweet  polarity  sentiment\n",
       "0  johnkrasinski saw quietplacemovie monday tryin...  0.000000        0.0\n",
       "1  rt quietplacemovie silence golden experience a...  0.300000        1.0\n",
       "2  wan na know felt quietplacemovie order l popco...  0.066667        1.0\n",
       "3  rt quietplacemovie xe x x cmy job tell story f...  0.285714        1.0\n",
       "4  capegirl quietplacemovie always movie date xf ...  0.000000        0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 : Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = [ tweet for index, tweet in enumerate(df_twitter['clean_Tweet']) if df_twitter['sentiment'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(df_twitter['clean_Tweet']) if df_twitter['sentiment'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(df_twitter['clean_Tweet']) if df_twitter['sentiment'][index] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive tweets: 59.336609336609335%\n",
      "Percentage of neutral tweets: 32.98525798525799%\n",
      "Percentage of negative tweets: 7.678132678132678%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(df_twitter['clean_Tweet'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(df_twitter['clean_Tweet'])))\n",
    "print(\"Percentage of negative tweets: {}%\".format(len(neg_tweets)*100/len(df_twitter['clean_Tweet'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like the audience really loved the movie. Most of the tweets are postive, we have very less negative tweets. The dataset looks imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import metrics\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_twitter['clean_Tweet'].values\n",
    "y = df_twitter['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The classification algorithm will need feature vectors, therefore we will convert our tweets into the Bag of Words (BoW) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)        \n",
    "        \n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_test,columns = ['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_tfidf,y_train)\n",
    "prediction['Naive_Bayes'] = classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   3,  26],\n",
       "       [  0,  53,  61],\n",
       "       [  0,   3, 180]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,prediction['Naive_Bayes'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.00      0.00      0.00        29\n",
      "        0.0       0.90      0.46      0.61       114\n",
      "        1.0       0.67      0.98      0.80       183\n",
      "\n",
      "avg / total       0.69      0.71      0.66       326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction['Naive_Bayes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postive Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_pos = [\"AQuietPlace is blowing past expectations and is now looking at an opening weekend around $40 million\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count_pos = count_vect.transform(tweet_pos)\n",
    "tweet_transformed = tfidf_transformer.transform(tweet_count_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(tweet_transformed)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the below tweet have words like scariest, afraid, scream the classifier is classifying it as positive, because the model has very little negative data to learn from. Therefore the imbalance has caused the data to overfit and thus predict badly on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_neg = [\"@quietplacemovie was the scariest horror film I’ve ever seen. I was afraid to scream.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count_neg = count_vect.transform(tweet_neg)\n",
    "tweet_transformed = tfidf_transformer.transform(tweet_count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(tweet_transformed)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier = tree.DecisionTreeClassifier(criterion = \"entropy\", random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifier.fit(X_train_tfidf,y_train)\n",
    "prediction['Decision_Tree'] = tree_classifier.predict(X_test_tfidf)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,  14,   8],\n",
       "       [  4,  89,  21],\n",
       "       [  3,  40, 140]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,prediction['Decision_Tree'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.50      0.24      0.33        29\n",
      "        0.0       0.62      0.78      0.69       114\n",
      "        1.0       0.83      0.77      0.80       183\n",
      "\n",
      "avg / total       0.73      0.72      0.72       326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction['Decision_Tree']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train_tfidf,y_train)\n",
    "prediction['Random_Forest'] = rf_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,  29],\n",
       "       [  0,  23,  91],\n",
       "       [  0,   0, 183]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,prediction['Random_Forest'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.00      0.00      0.00        29\n",
      "        0.0       1.00      0.20      0.34       114\n",
      "        1.0       0.60      1.00      0.75       183\n",
      "\n",
      "avg / total       0.69      0.63      0.54       326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction['Random_Forest']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = svm.SVC(kernel = 'linear',class_weight = 'balanced',random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier.fit(X_train_tfidf,y_train)\n",
    "prediction['SVM'] = svm_classifier.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,   4],\n",
       "       [  1, 105,   8],\n",
       "       [  4,  25, 154]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,prediction['SVM'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.67      0.34      0.45        29\n",
      "        0.0       0.72      0.92      0.81       114\n",
      "        1.0       0.93      0.84      0.88       183\n",
      "\n",
      "avg / total       0.83      0.83      0.82       326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediction['SVM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>Naive_Bayes</th>\n",
       "      <th>Decision_Tree</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random_Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  Naive_Bayes  Decision_Tree  SVM  Random_Forest\n",
       "273     1.0          1.0            1.0  1.0            1.0\n",
       "272     1.0          1.0            1.0  1.0            1.0\n",
       "187    -1.0          1.0            0.0  0.0            1.0\n",
       "50      1.0          1.0            1.0  1.0            1.0\n",
       "52      1.0          1.0            1.0  0.0            1.0\n",
       "55      1.0          1.0            1.0  1.0            1.0\n",
       "85      1.0          1.0            1.0  1.0            1.0\n",
       "172     1.0          1.0            1.0  1.0            1.0\n",
       "219     1.0          1.0            1.0  1.0            1.0\n",
       "263     1.0          1.0            1.0  1.0            1.0\n",
       "14      0.0          1.0            0.0  0.0            1.0\n",
       "148     1.0          1.0            0.0  1.0            1.0\n",
       "129     0.0          0.0            0.0  0.0            1.0\n",
       "240     0.0          0.0            1.0  0.0            1.0\n",
       "211     1.0          1.0            1.0  1.0            1.0\n",
       "91      1.0          1.0            1.0  1.0            1.0\n",
       "37      1.0          1.0            1.0  1.0            1.0\n",
       "313     1.0          1.0            1.0  1.0            1.0\n",
       "31      1.0          1.0            1.0  1.0            1.0\n",
       "147     1.0          1.0            0.0  1.0            1.0\n",
       "248     1.0          1.0            0.0  0.0            1.0\n",
       "251     1.0          1.0            1.0  1.0            1.0\n",
       "65      0.0          1.0            0.0  0.0            1.0\n",
       "119     0.0          1.0            0.0  0.0            1.0\n",
       "81     -1.0          1.0            1.0  0.0            1.0\n",
       "130     1.0          1.0            1.0  1.0            1.0\n",
       "36      1.0          1.0            1.0  1.0            1.0\n",
       "282     1.0          1.0            1.0 -1.0            1.0\n",
       "53      1.0          1.0            1.0  1.0            1.0\n",
       "290     0.0          1.0           -1.0  0.0            1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the classification reports we can see that SVM and Decision Tree perform comparatively better than the other classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
